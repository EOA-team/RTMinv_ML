{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In situ validation data\n",
    "\n",
    "Download data corresponding to LAI measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "base_dir = Path(os.path.dirname(os.path.realpath(\"__file__\"))).parent.parent\n",
    "sys.path.insert(0, os.path.join(base_dir, \"eodal\"))\n",
    "import eodal\n",
    "from eodal.config import get_settings\n",
    "from eodal.core.scene import SceneCollection\n",
    "from eodal.core.sensors.sentinel2 import Sentinel2\n",
    "from eodal.mapper.feature import Feature\n",
    "from eodal.mapper.filter import Filter\n",
    "from eodal.mapper.mapper import Mapper, MapperConfigs\n",
    "\n",
    "Settings = get_settings()\n",
    "# set to False to use a local data archive\n",
    "Settings.USE_STAC = True\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import geodesic\n",
    "from pyproj import Proj, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lai</th>\n",
       "      <th>location</th>\n",
       "      <th>protocol_version</th>\n",
       "      <th>Barcode Biomass Sample</th>\n",
       "      <th>Barcode Leaf Area Sample</th>\n",
       "      <th>Row Spacing [cm]</th>\n",
       "      <th>leaf_area_cm2</th>\n",
       "      <th>Comment</th>\n",
       "      <th>tmean_degC</th>\n",
       "      <th>gdd</th>\n",
       "      <th>gdd_cumsum</th>\n",
       "      <th>parcel</th>\n",
       "      <th>genotype</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-17 10:34:56</td>\n",
       "      <td>0.447264</td>\n",
       "      <td>Arenenberg</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>13508.0</td>\n",
       "      <td>13541</td>\n",
       "      <td>12.0</td>\n",
       "      <td>107.343424</td>\n",
       "      <td>None</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>694.5</td>\n",
       "      <td>Broatefaeld</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (1009573.514 6051626.822)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-28 09:07:15</td>\n",
       "      <td>0.331586</td>\n",
       "      <td>Arenenberg</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>13574.0</td>\n",
       "      <td>13637</td>\n",
       "      <td>13.0</td>\n",
       "      <td>43.106220</td>\n",
       "      <td>2nd fertilizer application (N)</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>802.1</td>\n",
       "      <td>Broatefaeld</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (1009584.963 6051647.736)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-11 09:48:44</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>Arenenberg</td>\n",
       "      <td>v3.0</td>\n",
       "      <td>14970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>1287.6</td>\n",
       "      <td>Broatefaeld</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (1009582.481 6051635.184)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-11 09:48:44</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>Arenenberg</td>\n",
       "      <td>v3.0</td>\n",
       "      <td>14970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>1287.6</td>\n",
       "      <td>Broatefaeld</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (1009582.481 6051635.184)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-19 13:14:04</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>Arenenberg</td>\n",
       "      <td>v3.0</td>\n",
       "      <td>15096.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1447.6</td>\n",
       "      <td>Broatefaeld</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (1009579.299 6051649.448)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date       lai    location protocol_version  \\\n",
       "0  2022-03-17 10:34:56  0.447264  Arenenberg             v2.0   \n",
       "1  2022-03-28 09:07:15  0.331586  Arenenberg             v2.0   \n",
       "2  2022-05-11 09:48:44  2.770000  Arenenberg             v3.0   \n",
       "3  2022-05-11 09:48:44  2.770000  Arenenberg             v3.0   \n",
       "4  2022-05-19 13:14:04  3.670000  Arenenberg             v3.0   \n",
       "\n",
       "   Barcode Biomass Sample Barcode Leaf Area Sample  Row Spacing [cm]  \\\n",
       "0                 13508.0                    13541              12.0   \n",
       "1                 13574.0                    13637              13.0   \n",
       "2                 14970.0                        0              14.0   \n",
       "3                 14970.0                        0              14.0   \n",
       "4                 15096.0                        0              13.0   \n",
       "\n",
       "   leaf_area_cm2                         Comment  tmean_degC   gdd  \\\n",
       "0     107.343424                            None         8.6   8.6   \n",
       "1      43.106220  2nd fertilizer application (N)        11.6  11.6   \n",
       "2       0.000000                            None        20.9  20.9   \n",
       "3       0.000000                            None        20.9  20.9   \n",
       "4       0.000000                            None        21.6  21.6   \n",
       "\n",
       "   gdd_cumsum       parcel genotype                         geometry  \n",
       "0       694.5  Broatefaeld     None  POINT (1009573.514 6051626.822)  \n",
       "1       802.1  Broatefaeld     None  POINT (1009584.963 6051647.736)  \n",
       "2      1287.6  Broatefaeld     None  POINT (1009582.481 6051635.184)  \n",
       "3      1287.6  Broatefaeld     None  POINT (1009582.481 6051635.184)  \n",
       "4      1447.6  Broatefaeld     None  POINT (1009579.299 6051649.448)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lai_path = base_dir.joinpath('data/in-situ_glai.gpkg')\n",
    "gdf = gpd.read_file(lai_path)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only locations of interest\n",
    "gdf = gdf[gdf.location.isin(['Strickhof', 'SwissFutureFarm', 'Witzwil'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get S2 spectra for pixels if they are cloud free\n",
    "# Craete pairs lai-spectra\n",
    "# Apply models and compute RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentinel2_scenes(\n",
    "    ds: Sentinel2,\n",
    "    target_resolution: int,\n",
    ") -> Sentinel2:\n",
    "    \"\"\"\n",
    "    Resample Sentinel-2 scenes and mask clouds, shadows, and snow\n",
    "    based on the Scene Classification Layer (SCL).\n",
    "\n",
    "    NOTE:\n",
    "        Depending on your needs, the pre-processing function can be\n",
    "        fully customized using the full power of EOdal and its\n",
    "    interfacing libraries!\n",
    "\n",
    "    :param target_resolution:\n",
    "        spatial target resolution to resample all bands to.\n",
    "    :returns:\n",
    "        resampled, cloud-masked Sentinel-2 scene.\n",
    "    \"\"\"\n",
    "    # resample scene\n",
    "    ds.resample(inplace=True, target_resolution=target_resolution)\n",
    "    # mask clouds, shadows, and snow\n",
    "    ds.mask_clouds_and_shadows(inplace=True, cloud_classes=[3, 8, 9, 10, 11])\n",
    "    return ds\n",
    "    \n",
    "\n",
    "def extract_s2_data(\n",
    "        aoi: gpd.GeoDataFrame,\n",
    "        time_start: datetime,\n",
    "        time_end: datetime,\n",
    "        scene_cloud_cover_threshold: float = 80,\n",
    "        feature_cloud_cover_threshold: float = 50,\n",
    "        spatial_resolution: int = 10\n",
    "    ) -> SceneCollection:\n",
    "    \"\"\"\n",
    "    Extracts Sentinel-2 data from the STAC SAT archive for a given area and time period.\n",
    "    Scenes that are too cloudy or contain nodata (blackfill), only, are discarded.\n",
    "\n",
    "    The processing level of the Sentinel-2 data is L2A (surface reflectance factors).\n",
    "\n",
    "    :param parcel:\n",
    "        field parcel geometry (defines the spatial extent to extract)\n",
    "    :param time_start:\n",
    "        start of the time period to extract\n",
    "    :param end_time:\n",
    "        end of the time period to extract\n",
    "    :param scene_cloud_cover_threshold:\n",
    "        scene-wide cloudy pixel percentage (from Sentinel-2 metadata) to filter out scenes\n",
    "        with too high cloud coverage values [0-100%]\n",
    "    :param feature_cloud_cover_threshold:\n",
    "        cloudy pixel percentage [0-100%] on the parcel level. Only if the parcel has a\n",
    "        lower percentual share of cloudy pixels (based on the scene classification layer) than\n",
    "        the threshold specified, the Sentinel-2 observation is kept\n",
    "    :param spatial_resolution:\n",
    "        spatial resolution of the Sentinel-2 data in meters (Def: 10m)\n",
    "    :param resampling_method:\n",
    "        spatial resampling method for those Sentinel-2 bands not available in the target\n",
    "        resolution. Nearest Neighbor by default\n",
    "    :returns:\n",
    "        dictionary with the list of scenes for the field parcel (`feature_scenes`), the\n",
    "        DataFrame of (un)used scenes and the reason for not using plus some basic scene\n",
    "        metadata (`scene_properties`)\n",
    "    \"\"\"\n",
    "    # setup the metadata filters (cloud cover and processing level)\n",
    "    metadata_filters = [\n",
    "        Filter('cloudy_pixel_percentage','<', scene_cloud_cover_threshold),\n",
    "        Filter('processing_level', '==', 'Level-2A')\n",
    "    ]\n",
    "    # setup the spatial feature for extracting data\n",
    "    feature = Feature.from_geoseries(aoi.geometry)\n",
    "    \n",
    "    # set up mapping configs\n",
    "    mapper_configs = MapperConfigs(\n",
    "        collection='sentinel2-msi',\n",
    "        time_start=time_start,\n",
    "        time_end=time_end,\n",
    "        feature=feature,\n",
    "        metadata_filters=metadata_filters\n",
    "    )\n",
    "\n",
    "    # get a new mapper instance. Set sensor to `sentinel2`\n",
    "    mapper = Mapper(mapper_configs)\n",
    "\n",
    "    # query the STAC (looks for available scenes in the selected spatio-temporal range)\n",
    "    mapper.query_scenes()\n",
    "\n",
    "    # get observations (loads the actual Sentinel2 scenes)\n",
    "    # the data is extract for the extent of the parcel\n",
    "    scene_kwargs = {\n",
    "        'scene_constructor': Sentinel2.from_safe,            # this tells the mapper how to read and load the data (i.e., Sentinel-2 scenes)\n",
    "        'scene_constructor_kwargs': {},                      # here you could specify which bands to read\n",
    "        'scene_modifier': preprocess_sentinel2_scenes,       # this tells the mapper about (optional) pre-processing of the loaded scenes (must be a callable)\n",
    "        'scene_modifier_kwargs': {'target_resolution': 10}   # here, you have to specify the value of the arguments the `scene_modifier` requires\n",
    "    }\n",
    "    mapper.load_scenes(scene_kwargs=scene_kwargs)\n",
    "\n",
    "    # loop over available Sentinel-2 scenes stored in mapper.data as a EOdal SceneCollection and check\n",
    "    # for no-data. These scenes will be removed from the SceneCollection\n",
    "    scenes_to_del = []\n",
    "    mapper.metadata['scene_used'] = 'yes'\n",
    "\n",
    "    if mapper.data is not None:\n",
    "        for scene_id, scene in mapper.data:\n",
    "\n",
    "            # check if scene is blackfilled (nodata); if yes continue\n",
    "            if scene.is_blackfilled:\n",
    "                scenes_to_del.append(scene_id)\n",
    "                mapper.metadata.loc[mapper.metadata.sensing_time.dt.strftime('%Y-%m-%d %H:%M') == scene_id.strftime('%Y-%m-%d %H:%M')[0:16], 'scene_used'] = 'No [blackfill]'\n",
    "                continue\n",
    "\n",
    "            # check cloud coverage (including shadows and snow) of the field parcel\n",
    "            feature_cloud_cover = scene.get_cloudy_pixel_percentage(cloud_classes=[3, 8, 9, 10, 11])\n",
    "\n",
    "            # if the scene is too cloudy, we skip it\n",
    "            if feature_cloud_cover > feature_cloud_cover_threshold:\n",
    "                scenes_to_del.append(scene_id)\n",
    "                mapper.metadata.loc[mapper.metadata.sensing_time.dt.strftime('%Y-%m-%d %H:%M') == scene_id.strftime('%Y-%m-%d %H:%M')[0:16], 'scene_used'] = 'No [clouds]'\n",
    "                continue\n",
    "\n",
    "        # delete scenes containing only no-data\n",
    "        for scene_id in scenes_to_del:\n",
    "            del mapper.data[scene_id]\n",
    "\n",
    "    \n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 17:34:16,804 eodal        INFO     Starting extraction of sentinel2 scenes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 17:34:41,911 eodal        INFO     Finished extraction of sentinel2 scenes\n"
     ]
    }
   ],
   "source": [
    "s2_data = extract_s2_data(\n",
    "  aoi=gdf.head(2).dissolve(),\n",
    "  time_start=datetime(2017,3,1),\n",
    "  time_end=datetime(2017,5,31)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_id, scene in s2_data.data:\n",
    "  pixs = scene.to_dataframe()\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_date = gdf.head(2)\n",
    "gdf_date = gdf_date.to_crs('EPSG:4326')\n",
    "pixs = pixs.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(point, tree):\n",
    "    ''' \n",
    "    Find the nearest point in pixs for each point in gdf_date\n",
    "    '''\n",
    "    _, index = tree.query((point.x, point.y))\n",
    "    return pixs.iloc[index]\n",
    "\n",
    "def compute_distance(row):\n",
    "    return geodesic((row['geometry'].y, row['geometry'].x), (row['geometry_s2'].y, row['geometry_s2'].x)).meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/eo-nas1/eoa-share/projects/010_CropCovEO/eodal/eodal/mapper/mapper.py:887: UserWarning: No scenes were found - consider modifying your search criteria\n",
      "  warnings.warn(\n",
      "/mnt/eo-nas1/eoa-share/projects/010_CropCovEO/eodal/eodal/mapper/mapper.py:887: UserWarning: No scenes were found - consider modifying your search criteria\n",
      "  warnings.warn(\n",
      "/mnt/eo-nas1/eoa-share/projects/010_CropCovEO/eodal/eodal/mapper/mapper.py:887: UserWarning: No scenes were found - consider modifying your search criteria\n",
      "  warnings.warn(\n",
      "2024-02-02 17:19:02,610 eodal        INFO     Starting extraction of sentinel2 scenes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 17:30:54,202 eodal        INFO     Starting extraction of sentinel2 scenes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Loop over dates of val data\n",
    "# Query s2 data for those dates\n",
    "# Keep pixel closest to geom\n",
    "\n",
    "val_df = pd.DataFrame()\n",
    "\n",
    "for d in gdf['date']:\n",
    "  try:\n",
    "    s2_data = extract_s2_data(\n",
    "      aoi=gdf.dissolve(),\n",
    "      time_start=pd.to_datetime(d), \n",
    "      time_end=pd.to_datetime(d) + timedelta(days=1)\n",
    "    )\n",
    "  except:\n",
    "    pass\n",
    "    \n",
    "  if s2_data.data is not None:\n",
    "    for scene_id, scene in s2_data.data:\n",
    "      pixs = scene.to_dataframe()\n",
    "      pixs = pixs.to_crs('EPSG:4326')\n",
    "      \n",
    "      # Find S2-data closest (within 10m) to validation data for that date\n",
    "      gdf_date = gdf[gdf['date'] == d]\n",
    "      gdf_date = gdf.date.to_crs(pixs.crs) # to meters, EPSG:32632\n",
    "\n",
    "      pixs_tree = cKDTree(pixs['geometry'].apply(lambda geom: (geom.x, geom.y)).tolist())\n",
    "\n",
    "      # Apply the function to each point in gdf_date\n",
    "      nearest_points = gdf_date['geometry'].apply(lambda point: find_nearest(point, pixs_tree))\n",
    "      nearest_points = nearest_points.rename(columns={'geometry': 'geometry_s2'})\n",
    "      gdf_date = pd.concat([gdf_date[['date', 'lai', 'location', 'geometry']], nearest_points], axis=1)\n",
    "\n",
    "      # # Keep if less than 10m away to ensure its the right pixel\n",
    "      gdf_date['distance'] = gdf_date.apply(compute_distance, axis=1)      \n",
    "      gdf_date = gdf_date[gdf_date['distance'] <10]\n",
    "      \n",
    "      # Save lai and spectra \n",
    "      if (len(gdf_date)):\n",
    "        val_df = pd.concat([val_df, gdf_date[['lai', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12',]]])\n",
    "\n",
    "\n",
    "\n",
    "# Save in-situ val data\n",
    "data_path = base_dir.joinpath(f'results/validation_data.pkl')\n",
    "with open(data_path, 'wb+') as dst:\n",
    "    pickle.dump(val_df, dst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10_cropcoveo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
