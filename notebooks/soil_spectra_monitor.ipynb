{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse soil spectra in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import List\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.interpolate import interp1d, pchip_interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "base_dir = Path(os.path.dirname(os.path.realpath(\"__file__\"))).parent.parent\n",
    "sys.path.insert(0, os.path.join(base_dir, \"eodal\"))\n",
    "import eodal\n",
    "\n",
    "from datetime import datetime\n",
    "from eodal.config import get_settings\n",
    "from eodal.core.scene import SceneCollection\n",
    "from eodal.core.sensors.sentinel2 import Sentinel2\n",
    "from eodal.mapper.feature import Feature\n",
    "from eodal.mapper.filter import Filter\n",
    "from eodal.mapper.mapper import Mapper, MapperConfigs\n",
    "from eodal.utils.reprojection import infer_utm_zone\n",
    "\n",
    "Settings = get_settings()\n",
    "# set to False to use a local data archive\n",
    "Settings.USE_STAC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample EO data in a small known field\n",
    "# Plot field in time\n",
    "# Plot a corresponding central pixel's spectra\n",
    "# Observe what happens during bare soil moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data for a field (1 year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentinel2_scenes(\n",
    "    ds: Sentinel2,\n",
    "    target_resolution: int,\n",
    "    ) -> Sentinel2:\n",
    "    \"\"\"\n",
    "    Resample Sentinel-2 scenes and mask clouds, shadows, and snow\n",
    "    based on the Scene Classification Layer (SCL).\n",
    "\n",
    "    NOTE:\n",
    "        Depending on your needs, the pre-processing function can be\n",
    "        fully customized using the full power of EOdal and its\n",
    "    interfacing libraries!\n",
    "\n",
    "    :param target_resolution:\n",
    "        spatial target resolution to resample all bands to.\n",
    "    :returns:\n",
    "        resampled, cloud-masked Sentinel-2 scene.\n",
    "    \"\"\"\n",
    "    # resample scene\n",
    "    ds.resample(inplace=True, target_resolution=target_resolution)\n",
    "    # mask clouds, shadows, and snow\n",
    "    ds.mask_clouds_and_shadows(inplace=True, cloud_classes=[3, 8, 9, 10, 11])\n",
    "    return ds\n",
    "\n",
    "\n",
    "def extract_s2_data(\n",
    "        aoi: gpd.GeoDataFrame,\n",
    "        time_start: datetime,\n",
    "        time_end: datetime,\n",
    "        scene_cloud_cover_threshold: float = 50,\n",
    "        feature_cloud_cover_threshold: float = 80,\n",
    "        spatial_resolution: int = 10\n",
    "    ) -> SceneCollection:\n",
    "    \"\"\"\n",
    "    Extracts Sentinel-2 data from the STAC SAT archive for a given area and time period.\n",
    "    Scenes that are too cloudy or contain nodata (blackfill), only, are discarded.\n",
    "    Keep only bare soil pixels\n",
    "\n",
    "    The processing level of the Sentinel-2 data is L2A (surface reflectance factors).\n",
    "\n",
    "    :param parcel:\n",
    "        field parcel geometry (defines the spatial extent to extract)\n",
    "    :param time_start:\n",
    "        start of the time period to extract\n",
    "    :param end_time:\n",
    "        end of the time period to extract\n",
    "    :param scene_cloud_cover_threshold:\n",
    "        scene-wide cloudy pixel percentage (from Sentinel-2 metadata) to filter out scenes\n",
    "        with too high cloud coverage values [0-100%]\n",
    "    :param feature_cloud_cover_threshold:\n",
    "        cloudy pixel percentage [0-100%] on the parcel level. Only if the parcel has a\n",
    "        lower percentual share of cloudy pixels (based on the scene classification layer) than\n",
    "        the threshold specified, the Sentinel-2 observation is kept\n",
    "    :param spatial_resolution:\n",
    "        spatial resolution of the Sentinel-2 data in meters (Def: 10m)\n",
    "    :param resampling_method:\n",
    "        spatial resampling method for those Sentinel-2 bands not available in the target\n",
    "        resolution. Nearest Neighbor by default\n",
    "    :returns:\n",
    "        dictionary with the list of scenes for the field parcel (`feature_scenes`), the\n",
    "        DataFrame of (un)used scenes and the reason for not using plus some basic scene\n",
    "        metadata (`scene_properties`)\n",
    "    \"\"\"\n",
    "    # setup the metadata filters (cloud cover and processing level)\n",
    "    metadata_filters = [\n",
    "        Filter('cloudy_pixel_percentage','<', scene_cloud_cover_threshold),\n",
    "        Filter('processing_level', '==', 'Level-2A')\n",
    "    ]\n",
    "    # setup the spatial feature for extracting data\n",
    "    feature = Feature.from_geoseries(aoi.geometry)\n",
    "    \n",
    "    # set up mapping configs\n",
    "    mapper_configs = MapperConfigs(\n",
    "        collection='sentinel2-msi',\n",
    "        time_start=time_start,\n",
    "        time_end=time_end,\n",
    "        feature=feature,\n",
    "        metadata_filters=metadata_filters\n",
    "    )\n",
    "\n",
    "    # get a new mapper instance. Set sensor to `sentinel2`\n",
    "    mapper = Mapper(mapper_configs)\n",
    "\n",
    "    # query the STAC (looks for available scenes in the selected spatio-temporal range)\n",
    "    mapper.query_scenes()\n",
    "\n",
    "    # get observations (loads the actual Sentinel2 scenes)\n",
    "    # the data is extract for the extent of the parcel\n",
    "    scene_kwargs = {\n",
    "        'scene_constructor': Sentinel2.from_safe,            # this tells the mapper how to read and load the data (i.e., Sentinel-2 scenes)\n",
    "        'scene_constructor_kwargs': {'band_selection': ['B01','B02','B03', 'B04', 'B05', 'B06', 'B07', 'B08','B8A', 'B11', 'B12', 'SCL']}, # here you could specify which bands to read\n",
    "        'scene_modifier': preprocess_sentinel2_scenes,       # this tells the mapper about (optional) pre-processing of the loaded scenes (must be a callable)\n",
    "        'scene_modifier_kwargs': {'target_resolution': spatial_resolution\n",
    "        }   # here, you have to specify the value of the arguments the `scene_modifier` requires\n",
    "    }\n",
    "\n",
    "    mapper.load_scenes(scene_kwargs=scene_kwargs)\n",
    "\n",
    "    # loop over available Sentinel-2 scenes stored in mapper.data as a EOdal SceneCollection and check\n",
    "    # for no-data. These scenes will be removed from the SceneCollection\n",
    "    scenes_to_del = []\n",
    "    mapper.metadata['scene_used'] = 'yes'\n",
    "\n",
    "    if mapper.data is not None:\n",
    "        for scene_id, scene in mapper.data:\n",
    "\n",
    "            # check if scene is blackfilled (nodata); if yes continue\n",
    "            if scene.is_blackfilled:\n",
    "                scenes_to_del.append(scene_id)\n",
    "                mapper.metadata.loc[mapper.metadata.sensing_time.dt.strftime('%Y-%m-%d %H:%M') == scene_id.strftime('%Y-%m-%d %H:%M')[0:16], 'scene_used'] = 'No [blackfill]'\n",
    "                continue\n",
    "\n",
    "            # check cloud coverage (including shadows and snow) of the field parcel\n",
    "            feature_cloud_cover = scene.get_cloudy_pixel_percentage(cloud_classes=[3, 8, 9, 10, 11])\n",
    "\n",
    "            # if the scene is too cloudy, we skip it\n",
    "            if feature_cloud_cover > feature_cloud_cover_threshold:\n",
    "                scenes_to_del.append(scene_id)\n",
    "                mapper.metadata.loc[mapper.metadata.sensing_time.dt.strftime('%Y-%m-%d %H:%M') == scene_id.strftime('%Y-%m-%d %H:%M')[0:16], 'scene_used'] = 'No [clouds]'\n",
    "                continue\n",
    "\n",
    "            # calculate the NDVI and NBR2\n",
    "            scene.calc_si('NDVI', inplace=True)\n",
    "            scene.calc_si('NBR2', inplace=True)\n",
    "\n",
    "            \"\"\"\n",
    "            # Check if there are any bare soil pixels\n",
    "            ndvi = scene.get_band('NDVI').values\n",
    "            nbr2 =  scene.get_band('NBR2').values\n",
    "            ndvi.fill_value = np.nan\n",
    "            nbr2.fill_value = np.nan\n",
    "            bare_condition = (0 < ndvi) & (ndvi <= 0.25) & (nbr2 <= 0.075)\n",
    "            bare_soil = np.ma.masked_array(ndvi.data, mask=~bare_condition)\n",
    "            if not np.sum(~bare_soil.mask): # all pixels are masked -> no bare soil\n",
    "                scenes_to_del.append(scene_id)\n",
    "            else:\n",
    "                #print(scene_id, np.sum(~bare_soil.mask))\n",
    "                scene.mask(bare_soil.mask, keep_mask_values=True, inplace=True)\n",
    "                # Save the number of bare soil pixels\n",
    "                mapper.metadata.loc[mapper.metadata['sensing_date'] == scene_id.date(), 'n_bare'] = np.sum(~bare_soil.mask)\n",
    "            \"\"\"\n",
    "            \n",
    "                \n",
    "        # delete scenes too cloudy or containing only no-data or with no bare soil pixels\n",
    "        for scene_id in scenes_to_del:\n",
    "            del mapper.data[scene_id]\n",
    "        # Keep only metadata for corresponding scenes\n",
    "        dates_to_del = [scene_id.date() for scene_id in scenes_to_del]\n",
    "        mapper.metadata = mapper.metadata[~mapper.metadata['sensing_date'].isin(dates_to_del)]\n",
    "    \n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from Strickhof farm (Eschikon)\n",
    "shp_path = base_dir.joinpath(f'data/Strickhof.shp')\n",
    "save_path = base_dir.joinpath(f'results/monitor_BS_data.pkl')\n",
    "metadata_path = save_path.with_name(save_path.name.replace('data', 'metadata'))\n",
    "\n",
    "geom = gpd.read_file(shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 13:18:36,336 eodal        INFO     Starting extraction of sentinel2 scenes\n",
      "2024-03-06 13:20:26,700 eodal        INFO     Finished extraction of sentinel2 scenes\n"
     ]
    }
   ],
   "source": [
    "res_baresoil = extract_s2_data(\n",
    "    aoi=geom.dissolve(), \n",
    "    time_start=datetime(2021,1,1),\n",
    "    time_end=datetime(2021,12,31),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for future use\n",
    "with open(save_path, 'wb+') as dst:\n",
    "  dst.write(res_baresoil.data.to_pickle())     \n",
    "with open(metadata_path, 'wb+') as dst:\n",
    "  pickle.dump(res_baresoil.metadata, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoll = SceneCollection.from_pickle(stream=save_path)\n",
    "metadata = pd.read_pickle(metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View data in time and compare spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scenes(res: SceneCollection) -> None:\n",
    "    \n",
    "    ts = scoll.timestamps\n",
    "    ts_datetime = [datetime.strptime(t, '%Y-%m-%d %H:%M:%S') for t in ts]\n",
    "\n",
    "    # Plot month by month\n",
    "    for i in range(1, 13):\n",
    "        # Filter elements for the current month\n",
    "        month_ts = [t for t in ts_datetime if t.month == i]\n",
    "        month_ts_str = [timestamp.strftime('%Y-%m-%d %H:%M:%S') for timestamp in month_ts]\n",
    "        \n",
    "        # scoll.__getitem__(month_ts_str[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(ncols=len(res), nrows=12, figsize=(26,14))\n",
    "idx = 0\n",
    "for scene_id, scene in res:\n",
    "    scene.plot_multiple_bands(\n",
    "        band_selection=['nir_1', 'red' ,'green'],\n",
    "        ax=axes[0,idx]\n",
    "    )\n",
    "    axes[0,idx].set_title(scene_id)\n",
    "    axes[0,idx].set_xlabel('')\n",
    "    axes[0,idx].get_xaxis().set_ticks([])\n",
    "        # plot the MSAVI\n",
    "    scene.plot_band(\n",
    "        'MSAVI',\n",
    "        colormap='summer',\n",
    "        colorbar_label='MSAVI [-]',\n",
    "        vmin=0,\n",
    "        vmax=0.8,\n",
    "        ax=axes[1,idx]\n",
    "    )\n",
    "    # plot the MSAVI\n",
    "    scene.plot_band(\n",
    "        'NDVI',\n",
    "        colormap='summer',\n",
    "        colorbar_label='NDVI [-]',\n",
    "        vmin=0,\n",
    "        vmax=1.,\n",
    "        ax=axes[2,idx]\n",
    "    )\n",
    "    # set y and x ticks as well as title strings at the outer bounds, only, of to improve readability\n",
    "    if idx > 0:\n",
    "        for jdx in range(3):\n",
    "            axes[jdx,idx].get_yaxis().set_ticks([])\n",
    "            axes[jdx,idx].set_ylabel('')\n",
    "    for jdx in range(1,3):\n",
    "        for tdx in range(len(res)):\n",
    "            axes[jdx,tdx].set_title('')\n",
    "            if jdx == 1:\n",
    "                axes[jdx,tdx].get_xaxis().set_ticks([])\n",
    "                axes[jdx,tdx].set_xlabel('')\n",
    "    idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10_cropcoveo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
